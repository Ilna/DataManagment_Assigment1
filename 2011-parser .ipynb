{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# parse books json\n",
    "df = pd.read_json (r'C:/Users/IliaMalfa/DataManagment1/goodreads_books_comics_graphic.json', lines=True)\n",
    "\n",
    "# remove empty publisher name rows\n",
    "df = df[~df['publisher'].isin([''])]\n",
    "df = df.drop_duplicates(subset=['publisher'])\n",
    "publisherDataFrame = df[['publisher','language_code']].copy()\n",
    "\n",
    "print (df.columns.values);\n",
    "print(df.shape)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate random contact phone\n",
    "contactPhoneData =np.random.randint(low=1000000000, high=9999999999,size =len(publisherDataFrame), dtype=np.int64)\n",
    "publisherDataFrame['contact_phone'] = contactPhoneData\n",
    "publisherDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate random adress\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "fakeAddresses = []\n",
    "\n",
    "for _ in range(len(publisherDataFrame)):\n",
    "    fakeAddresses.append(format(fake.address()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the lenght of address data created is equal to the dataframe length\n",
    "len(fakeAddresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create address column at publisherDataFrame\n",
    "publisherDataFrame['address'] = fakeAddresses\n",
    "publisherDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename publisherDataFrame columns\n",
    "publisherDataFrame.rename(columns = {'publisher' :'name'}, inplace = True)\n",
    "publisherDataFrame.rename(columns = {'language_code':'country_of_headquarters'}, inplace = True)\n",
    "publisherDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAY 2 QUICK WAY\n",
    "# connect to the db and pass the data\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "from io import StringIO\n",
    "\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"ComicShop\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"mypass\"\n",
    "}\n",
    "\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "conn = connect(param_dic)\n",
    "\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    print(table)\n",
    "    print(cols)\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "    \n",
    "table = \"publishers\"\n",
    "execute_values(conn, publisherDataFrame, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# parse authors json\n",
    "df = pd.read_json (r'C:/Users/IliaMalfa/DataManagment1/goodreads_book_authors.json', lines=True)\n",
    "\n",
    "print (df.columns.values);\n",
    "print(df.shape)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a authors dataframe with the desirable columns\n",
    "authorsDataFrame = df[['author_id','name']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess the gender by the firstName, \n",
    "# if the first argument of name is a salutation and contains . then check the second argument\n",
    "import gender_guesser.detector as gender\n",
    "d = gender.Detector()\n",
    "data =[]\n",
    "\n",
    "df.name.replace(to_replace='', value=None, regex=True,inplace=True) \n",
    "for index, row in df.iterrows():\n",
    "    firstName= row['name'].split()[0]\n",
    "    try:\n",
    "        firstName.index(\".\")\n",
    "    except ValueError:\n",
    "        print(\"occurred an exception\")\n",
    "    else:\n",
    "         try:\n",
    "            firstName= row['name'].split()[1]\n",
    "         except:\n",
    "            print(\"here occurred an exception\")\n",
    "         else:       \n",
    "            firstName= row['name'].split()[1]\n",
    "    gender = d.get_gender(firstName)\n",
    "    print(firstName +\" :\"+gender)\n",
    "    data.append(format(gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the lenght of gender data created is equal to the dataframe length\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create gender column at authorsDataFrame\n",
    "authorsDataFrame['gender'] = data\n",
    "authorsDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename authorsDataFrame columns\n",
    "authorsDataFrame.rename(columns = {'author_id':'id'}, inplace = True)\n",
    "authorsDataFrame.rename(columns = {'name':'author_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAY 2 QUICK WAY\n",
    "# connect to the db and pass the data\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "from io import StringIO\n",
    "\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"ComicShop\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"mypass\"\n",
    "}\n",
    "\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "conn = connect(param_dic)\n",
    "\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "    \n",
    "table = \"authors\"\n",
    "execute_values(conn, authorsDataFrame, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# path to books json file\n",
    "p = Path(r'C:/Users/IliaMalfa/DataManagment1/goodreads_books_comics_graphic.json')\n",
    "\n",
    "# load json\n",
    "books = []\n",
    "for line in open(p, 'r'):\n",
    "    books.append(json.loads(line))\n",
    "\n",
    "# create dataframe with normalized authors for the author values that are nested\n",
    "df = pd.json_normalize(books, record_path='authors', meta=['isbn','title','author_id', 'publisher','publication_year', 'description', 'book_id'], record_prefix='authors_',errors='ignore')\n",
    "\n",
    "# remove empty isbn rows and drow isbn duplicates\n",
    "df = df[~df['isbn'].isin([''])]\n",
    "df = df.drop_duplicates(subset=['isbn'])\n",
    "bookDataframe = df[['isbn','title', 'authors_author_id', 'publisher', 'publication_year', 'description', 'book_id']].copy()\n",
    "\n",
    "\n",
    "bookDataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add price column as a fixed point attribute with 2 decimal digits\n",
    "data = np.round(np.random.uniform(5,40,len(bookDataframe)),2)\n",
    "bookDataframe['price'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rename publisherDataFrame columns\n",
    "bookDataframe.rename(columns = {'authors_author_id' :'author_id'}, inplace = True)\n",
    "bookDataframe.rename(columns = {'description':'short_description'}, inplace = True)\n",
    "bookDataframe.rename(columns = {'book_id':'id'}, inplace = True)\n",
    "bookDataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAY 2 QUICK WAY\n",
    "# connect to the db and pass the data\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "from io import StringIO\n",
    "\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"ComicShop\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"mypass\"\n",
    "}\n",
    "\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "conn = connect(param_dic)\n",
    "\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    print(table)\n",
    "    print(cols)\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "    \n",
    "table = \"books\"\n",
    "execute_values(conn, bookDataframe, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors With Books And Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# path to books json file\n",
    "p = Path(r'C:/Users/IliaMalfa/DataManagment1/goodreads_books_comics_graphic.json')\n",
    "\n",
    "# load json\n",
    "books = []\n",
    "for line in open(p, 'r'):\n",
    "    books.append(json.loads(line))\n",
    "\n",
    "# create dataframe with normalized authors for the author values that are nested\n",
    "df = pd.json_normalize(books, record_path='authors', meta=['isbn','title','author_id', 'role', 'publisher','publication_year', 'description', 'language_code', 'book_id'], record_prefix='authors_',errors='ignore')\n",
    "\n",
    "# remove empty isbn\n",
    "df = df[~df['isbn'].isin([''])]\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep author_id and role to make it a new table\n",
    "authorsWithRolesAndNationalityDataframe = df[['authors_author_id','isbn','authors_role', 'language_code', 'book_id']].copy()\n",
    "authorsWithRolesAndNationalityDataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename authorsWithRolesAndNationalityDataframe columns\n",
    "authorsWithRolesAndNationalityDataframe.rename(columns = {'authors_author_id' :'author_id'}, inplace = True)\n",
    "authorsWithRolesAndNationalityDataframe.rename(columns = {'isbn':'book_isbn'}, inplace = True)\n",
    "authorsWithRolesAndNationalityDataframe.rename(columns = {'authors_role':'author_role'}, inplace = True)\n",
    "authorsWithRolesAndNationalityDataframe.rename(columns = {'language_code':'author_nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAY 2 QUICK WAY\n",
    "# connect to the db and pass the data\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "from io import StringIO\n",
    "\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"ComicShop\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"mypass\"\n",
    "}\n",
    "\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "conn = connect(param_dic)\n",
    "\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    print(table)\n",
    "    print(cols)\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "    \n",
    "table = \"bookswithauthorsandroles\"\n",
    "execute_values(conn, authorsWithRolesAndNationalityDataframe, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# parse authors json\n",
    "df = pd.read_json (r'C:/Users/IliaMalfa/DataManagment1/goodreads_reviews_comics_graphic.json', lines=True)\n",
    "print (df.columns.values);\n",
    "print(df.shape)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty isbn\n",
    "df = df[~df['book_id'].isin([''])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a authors dataframe with the desirable columns\n",
    "reviewsDataFrame = df[['review_id','book_id','rating','review_text', 'date_added', 'user_id']].copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data= []\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    datetime_object = datetime.strptime(row['date_added'], '%a %b %d %H:%M:%S -%f %Y')\n",
    "    data.append(datetime_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename reviewsDataFrame columns\n",
    "reviewsDataFrame.rename(columns = {'rating' :'score'}, inplace = True)\n",
    "reviewsDataFrame.rename(columns = {'date_added':'creation_timestamp'}, inplace = True)\n",
    "reviewsDataFrame.rename(columns = {'user_id':'nickName'}, inplace = True)\n",
    "reviewsDataFrame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nicknames based on every user grouped by the userId\n",
    "from faker import Faker\n",
    "from random import randint\n",
    "\n",
    "group_by_userId = reviewsDataFrame.groupby([\"nickName\"])[\"nickName\"]\n",
    "type(group_by_userId)\n",
    "len(group_by_userId)\n",
    "for i in group_by_userId:\n",
    "    reviewsDataFrame.loc[reviewsDataFrame['nickName'] == i[0], ['nickName']] = format(fake.name().split()[0]+str(randint(10,99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDataFrame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviewsDataFrame['creation_timestamp'] = data\n",
    "reviewsDataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAY 2 QUICK WAY\n",
    "# connect to the db and pass the data\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "from io import StringIO\n",
    "\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"ComicShop\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"mypass\"\n",
    "}\n",
    "\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "conn = connect(param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    print(table)\n",
    "    print(cols)\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "    \n",
    "table = \"reviews\"\n",
    "execute_values(conn, reviewsDataFrame, table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
